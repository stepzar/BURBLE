{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install transformers\n",
        "!nltk.download(\"wordnet\")\n",
        "!pip install jedi"
      ],
      "metadata": {
        "id": "mIA056DWXkUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79a6lq2ASGp6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForSeq2SeqLM, RobertaTokenizer, T5ForConditionalGeneration\n",
        "import torch\n",
        "from nltk.corpus import wordnet as wn\n",
        "import nltk\n",
        "\n",
        "\n",
        "path = \"eclipse_platform.csv\"\n",
        "\n",
        "df = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the models"
      ],
      "metadata": {
        "id": "RnSFfZy4uHrK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predict functions"
      ],
      "metadata": {
        "id": "4P4d42zEuoh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"papluca/xlm-roberta-base-language-detection\")\n",
        "\n",
        "def detect_language(text):\n",
        "    # Encode the text\n",
        "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
        "    # Get the logits for the text\n",
        "    logits = model(input_ids)[0]\n",
        "    # Get the class probabilities\n",
        "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "    # Get the class label\n",
        "    label_id = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    return label_id, probs[0][label_id].item()"
      ],
      "metadata": {
        "id": "KULrexS1cjx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pre-trained model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "\n",
        "def sentiment_analysis(text):\n",
        "    # Encode the text\n",
        "    input_ids = torch.tensor([tokenizer.encode(text, add_special_tokens=True)])\n",
        "    # Get the logits for the text\n",
        "    logits = model(input_ids)[0]\n",
        "    # Get the class probabilities\n",
        "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "    # Get the class label\n",
        "    label_id = torch.argmax(probs, dim=1).item()\n",
        "\n",
        "    if label_id == 0:\n",
        "      sentiment = \"negative\"\n",
        "    elif label_id == 1:\n",
        "      sentiment = \"neutral\"\n",
        "    else:\n",
        "      sentiment = \"positive\"\n",
        "\n",
        "    return sentiment, probs[0][label_id].item()\n",
        "  "
      ],
      "metadata": {
        "id": "eCDcjqpJ3WT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils functions"
      ],
      "metadata": {
        "id": "tj4knzbIkB2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_case(text):\n",
        "    camel_case = r'[a-z][A-Z][a-z]*'\n",
        "    snake_case = r'[a-z]+_[a-z]+'\n",
        "\n",
        "    if re.search(camel_case, text):\n",
        "        return True\n",
        "    elif re.search(snake_case, text):\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "metadata": {
        "id": "VaP01RwZkESK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_keywords(text):\n",
        "  keywords = open(\"drive/MyDrive/Tesi/keywords.txt\", \"r\").readlines()\n",
        "\n",
        "  to_analyze = text.split()\n",
        "\n",
        "  count = 0\n",
        "  for keyword in keywords:\n",
        "    count += to_analyze.count(keyword.replace(\"\\n\",\"\"))\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "MPvR93SPhJPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_symbols(text):\n",
        "  symbols = [\"{\",\"}\",\"(\",\")\",\";\",\"[\",\"]\",\"<\",\">\",\"=\"]\n",
        "\n",
        "  count = 0\n",
        "  for symbol in symbols:\n",
        "    count += text.count(symbol)\n",
        "  \n",
        "  return count"
      ],
      "metadata": {
        "id": "o-bo0X2BsjCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_punctuation(text):\n",
        "  count = 0\n",
        "  count += text.count(\". \")\n",
        "  count += text.count(\", \")\n",
        "  count += text.count(\"! \")\n",
        "  count += text.count(\"? \")\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "BD9SlEJbcPKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def percentage_of_spaces(text):\n",
        "  spaces = text.count(\" \")\n",
        "  chars = len(text)\n",
        "\n",
        "  return spaces/chars"
      ],
      "metadata": {
        "id": "BXZ99TQUgAmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score_to_words(score, text):\n",
        "  words = len(text.split())\n",
        "\n",
        "  return score/words"
      ],
      "metadata": {
        "id": "dTanUuieiD40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Select the bug report for example"
      ],
      "metadata": {
        "id": "ETzJqDReueys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1642 1776 60 85 857\n",
        "bug_rep_ex = df.loc[df[\"Issue_id\"] == 4615, \"Description\"].values[0]\n",
        "\n",
        "bug_rep_ex = bug_rep_ex.replace(\";;\",\"^\").replace(\"\\t\",\"\")\n",
        "bug_rep_ex"
      ],
      "metadata": {
        "id": "5lcBRAZYUU5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function"
      ],
      "metadata": {
        "id": "uv1wXXoy5jke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CLASSIFIER(bug_report,len_min_string_code,\n",
        "perc_len_min_string_code,perc_detect_language,\n",
        "point_check_case,perc_spaces,point_perc_of_spaces,\n",
        "point_sentiment,perc_score_to_words):\n",
        "score = 0\n",
        "  if len(bug_report) > 0:\n",
        "    if len(bug_report) < len_min_string_code and check_symbols(bug_report) >= perc_len_min_string_code * len(bug_report) or detect_language(bug_report)[1] < perc_detect_language:\n",
        "      score += check_keywords(bug_report)\n",
        "      score += check_symbols(bug_report)\n",
        "      score -= check_punctuation(bug_report)\n",
        "      \n",
        "      if check_case(bug_report):\n",
        "        score += point_check_case\n",
        "      \n",
        "      if percentage_of_spaces(bug_report) > perc_spaces:\n",
        "        score -= point_perc_of_spaces\n",
        "      \n",
        "      if sentiment_analysis(bug_report)[0] == \"positive\":\n",
        "        score -= point_sentiment\n",
        "      \n",
        "      return score_to_words(score, bug_report) > perc_score_to_words\n",
        "      \n",
        "  return False"
      ],
      "metadata": {
        "id": "2XfZV7QafSn0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}